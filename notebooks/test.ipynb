{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "worst-compilation",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hundred-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一つ上の階層からモジュールを参照できるようにする\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accepting-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モジュールの変更を自動的に反映する\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "moved-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from inputs import load_data\n",
    "# # XGB\n",
    "from models import XGB\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, LeaveOneOut\n",
    "from scipy.stats import uniform\n",
    "# Torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from models import TrainingDataset, Torch, transform_labels, restore_labels, train_model, validate_model, \\\n",
    "                   TestDataset, predict_test\n",
    "# Keras\n",
    "from keras import Sequential, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-subscription",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "premium-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "passive-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGB(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "square-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x = train_x#[:80]\n",
    "va_x = train_x#[80:]\n",
    "tr_y = train_y#[:80]\n",
    "va_y = train_y#[80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "amber-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = 5\n",
    "model.fit(tr_x, tr_y, va_x, va_y,\n",
    "          early_stopping_rounds=early_stopping,\n",
    "          verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "charitable-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "royal-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = test_x.index.to_numpy().reshape(-1, 1)\n",
    "preds = preds.reshape(-1, 1)\n",
    "submission = np.concatenate((index, preds), axis=1)\n",
    "submission = pd.DataFrame(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "potential-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('xgb.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-distance",
   "metadata": {},
   "source": [
    "### Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-roulette",
   "metadata": {},
   "source": [
    "#### Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "classical-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'random_state': [1],\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [1000],\n",
    "    'early_stopping_rounds': [50],\n",
    "    'max_depth': [20*(i+1) for i in range(5)],\n",
    "    'min_child_weight': [0.1, 0.5, 1, 2, 3, 5],\n",
    "    # 'gamma': [0, 0.1, 0.5, 1, 2, 3, 5],\n",
    "    # 'alpha': [0, 0.1, 0.5, 1, 2, 3, 5],\n",
    "    # 'subsample': np.linspace(0.1, 1, 10),\n",
    "    'colsample': np.linspace(0.1, 1, 10),\n",
    "    'lambda': [0, 0.1, 0.5, 1, 2, 3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "formed-mountain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 2100 candidates, totalling 8400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=3)]: Done 359 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=3)]: Done 642 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 1007 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 1452 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=3)]: Done 1979 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=3)]: Done 2586 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=3)]: Done 3275 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=3)]: Done 4044 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=3)]: Done 4895 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=3)]: Done 5826 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=3)]: Done 6839 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=3)]: Done 7932 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=3)]: Done 8400 out of 8400 | elapsed: 14.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:27:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { colsample, early_stopping_rounds } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGB()\n",
    "# Stratified KFold を使う場合\n",
    "gs = GridSearchCV(model, param_grid, cv=4, n_jobs=3, scoring='accuracy', verbose=2, refit=True)\n",
    "# # LeaveOneOut を使う場合\n",
    "# gs = GridSearchCV(model, param_grid, cv=LeaveOneOut(), n_jobs=3, scoring='accuracy', verbose=2, refit=True)\n",
    "gs = gs.fit(tr_x, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "future-investigator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best pararms are {'colsample': 0.1, 'early_stopping_rounds': 50, 'lambda': 1, 'learning_rate': 0.1, 'max_depth': 20, 'min_child_weight': 1, 'n_estimators': 1000, 'random_state': 1}\n",
      "best score is 0.756054131054131\n"
     ]
    }
   ],
   "source": [
    "print(f'best pararms are {gs.best_params_}')\n",
    "print(f'best score is {gs.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "alleged-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = gs.best_estimator_\n",
    "preds = model_best.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "thrown-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = test_x.index.to_numpy().reshape(-1, 1)\n",
    "preds = preds.reshape(-1, 1)\n",
    "submission = np.concatenate((index, preds), axis=1)\n",
    "submission = pd.DataFrame(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "vocal-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('xgb_gs.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-woman",
   "metadata": {},
   "source": [
    "#### Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "genetic-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'random_state': [1],\n",
    "    'learning_rate': uniform(loc=0.0001, scale=1),\n",
    "    'max_depth': [5*(i+1) for i in range(40)],\n",
    "    'n_estimators': [5*(i+1) for i in range(40)],\n",
    "    'early_stopping_rounds': [5*(i+1) for i in range(40)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cutting-familiar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:51:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { early_stopping_rounds, leaning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGB()\n",
    "# Stratified KFold を使う場合\n",
    "rs = RandomizedSearchCV(model, param_distributions, n_iter=100, n_jobs=3, scoring='accuracy', cv=4)\n",
    "# # LeaveOneOut を使う場合\n",
    "# rs = RandomizedSearchCV(model, param_distributions, n_iter=100, n_jobs=3, scoring='accuracy', cv=LeaveOneOut())\n",
    "search = rs.fit(tr_x, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "answering-azerbaijan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best pararms are {'early_stopping_rounds': 80, 'leaning_rate': 0.34780176766029813, 'max_depth': 120, 'n_estimators': 35, 'random_state': 1}\n",
      "best score is 0.7375356125356125\n"
     ]
    }
   ],
   "source": [
    "print(f'best pararms are {rs.best_params_}')\n",
    "print(f'best score is {rs.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sustainable-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = rs.best_estimator_\n",
    "preds = model_best.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "continental-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = test_x.index.to_numpy().reshape(-1, 1)\n",
    "preds = preds.reshape(-1, 1)\n",
    "submission = np.concatenate((index, preds), axis=1)\n",
    "submission = pd.DataFrame(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "final-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('xgb_rs.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-yugoslavia",
   "metadata": {},
   "source": [
    "#### HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "conventional-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x = train_x[:85]\n",
    "va_x = train_x[85:]\n",
    "tr_y = train_y[:85]\n",
    "va_y = train_y[85:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "engaging-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "parliamentary-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    \n",
    "    model = XGB()\n",
    "    model.fit(tr_x, tr_y)\n",
    "    va_pred = model.predict_proba(va_x)\n",
    "    # print(f'va_y: {va_y_}')\n",
    "    # print(f'va_pred: {va_pred}')\n",
    "    score = log_loss(va_y_, va_pred)\n",
    "    print(f'params: {params}, logloss:{score:.4f}')\n",
    "    \n",
    "    history.append((params, score))\n",
    "    return {'loss': score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "according-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'random_state': hp.choice('random_state', [1]),\n",
    "    'learning_rate': hp.choice('learning_rate', [0.1]),\n",
    "    'n_estimators': hp.choice('n_estimators', [1000]),\n",
    "    'early_stopping_rounds': hp.choice('early_stopping_rounds', [50]),\n",
    "    'max_depth': hp.quniform('max_depth', 0, 100, 5),\n",
    "    'min_child_weight': hp.uniform('min_child_weight', 0, 10),\n",
    "    'gamma': hp.uniform('gamma', 0, 10),\n",
    "    'alpha': hp.uniform('alpha', 0, 10),\n",
    "    'subsample': hp.quniform('subsample', 0, 1, 0.1),\n",
    "    'colsample': hp.quniform('colsample', 0, 1, 0.1),\n",
    "    'lambda': hp.uniform('lambda', 0, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "steady-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = [transform_labels(i) for i in va_y]\n",
    "va_y_ = np.identity(len(tr_y.unique()))[transformed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "north-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "max_evals = 500\n",
    "trials = Trials()\n",
    "history = []\n",
    "fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=max_evals, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "about-event",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'alpha': 2.000017767073363, 'colsample': 0.5, 'early_stopping_rounds': 50, 'gamma': 5.4447788686676235, 'lambda': 9.954496848033637, 'learning_rate': 0.1, 'max_depth': 80, 'min_child_weight': 0.4577317776079548, 'n_estimators': 1000, 'random_state': 1, 'subsample': 0.30000000000000004}, score: 1.5618\n"
     ]
    }
   ],
   "source": [
    "history = sorted(history, key=lambda tpl: tpl[1])\n",
    "best = history[0]\n",
    "print(f'best params: {best[0]}, score: {best[1]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "successful-paste",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:45:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { colsample, early_stopping_rounds } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGB()\n",
    "model.set_params(**best[0])\n",
    "model.fit(train_x, train_y)\n",
    "preds = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bored-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = test_x.index.to_numpy().reshape(-1, 1)\n",
    "preds = preds.reshape(-1, 1)\n",
    "submission = np.concatenate((index, preds), axis=1)\n",
    "submission = pd.DataFrame(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "tutorial-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('xgb_ho.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-suite",
   "metadata": {},
   "source": [
    "## Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "located-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TrainingDataset(target_transform = transform_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "valid-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.95\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adjusted-energy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X torch.Size([6, 9])\n",
      "Shape of y torch.Size([6]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "for X, y in val_dataloader:\n",
    "    print('Shape of X', X.shape)\n",
    "    print('Shape of y', y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "sufficient-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 9\n",
    "output_size = 6\n",
    "model = Torch(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "funky-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "threatened-procurement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.796193  [    0/  101]\n",
      "loss: 1.775526  [   20/  101]\n",
      "loss: 1.795517  [   40/  101]\n",
      "loss: 1.787526  [   60/  101]\n",
      "loss: 1.784987  [   80/  101]\n",
      "loss: 1.875845  [  100/  101]\n",
      "Test Error: \n",
      "Accuracy: 16.7%, Avg loss: 0.306299 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.795148  [    0/  101]\n",
      "loss: 1.775630  [   20/  101]\n",
      "loss: 1.796246  [   40/  101]\n",
      "loss: 1.788041  [   60/  101]\n",
      "loss: 1.785111  [   80/  101]\n",
      "loss: 1.871614  [  100/  101]\n",
      "Test Error: \n",
      "Accuracy: 16.7%, Avg loss: 0.305924 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.794282  [    0/  101]\n",
      "loss: 1.775714  [   20/  101]\n",
      "loss: 1.796897  [   40/  101]\n",
      "loss: 1.788494  [   60/  101]\n",
      "loss: 1.785205  [   80/  101]\n",
      "loss: 1.868060  [  100/  101]\n",
      "Test Error: \n",
      "Accuracy: 16.7%, Avg loss: 0.305613 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.793576  [    0/  101]\n",
      "loss: 1.775770  [   20/  101]\n",
      "loss: 1.797454  [   40/  101]\n",
      "loss: 1.788868  [   60/  101]\n",
      "loss: 1.785265  [   80/  101]\n",
      "loss: 1.865156  [  100/  101]\n",
      "Test Error: \n",
      "Accuracy: 0.0%, Avg loss: 0.305361 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.793004  [    0/  101]\n",
      "loss: 1.775794  [   20/  101]\n",
      "loss: 1.797907  [   40/  101]\n",
      "loss: 1.789159  [   60/  101]\n",
      "loss: 1.785291  [   80/  101]\n",
      "loss: 1.862840  [  100/  101]\n",
      "Test Error: \n",
      "Accuracy: 0.0%, Avg loss: 0.305161 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n-------------------------------')\n",
    "    train_model(train_dataloader, model, loss_fn, optimizer)\n",
    "    validate_model(val_dataloader, model, loss_fn)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "alone-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset()\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "preds = predict_test(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "interracial-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [restore_labels(p) for p in preds]\n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "meaningful-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "crude-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, test_x = load_data()\n",
    "index = test_x.index.to_numpy().reshape(-1, 1)\n",
    "preds = preds.reshape(-1, 1)\n",
    "submission = np.concatenate((index, preds), axis=1)\n",
    "submission = pd.DataFrame(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "selected-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('torch.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-advisory",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "limited-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_FOR_SUBMISSION = True\n",
    "validation_split = 0.0 if TRAINING_FOR_SUBMISSION else 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "tight-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "peaceful-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_y.unique())\n",
    "train_y = pd.get_dummies(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "contained-damages",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_66 (Dense)             (None, 64)                640       \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 5,190\n",
      "Trainable params: 5,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (train_x.shape[1],)\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "chemical-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "latest-least",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11/11 [==============================] - 0s 852us/step - loss: 8.0530 - accuracy: 0.1682\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 0s 789us/step - loss: 3.1567 - accuracy: 0.3551\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 0s 829us/step - loss: 2.0668 - accuracy: 0.3178\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 0s 903us/step - loss: 1.8164 - accuracy: 0.3738\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 0s 933us/step - loss: 1.5992 - accuracy: 0.4112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff84bd31290>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "dominant-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train_y.columns.tolist()\n",
    "preds = model.predict(test_x).argmax(axis=1)\n",
    "preds = [classes[pred] for pred in preds]\n",
    "preds = np.array(preds)\n",
    "preds = preds.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "missing-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "several-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = test_x.index.to_numpy().reshape(-1, 1)\n",
    "submission = np.concatenate((index, preds), axis=1)\n",
    "submission = pd.DataFrame(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "brave-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('keras.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-skating",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
