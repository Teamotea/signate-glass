{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "compatible-current",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "combined-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一つ上の階層からモジュールを参照できるようにする\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "crude-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モジュールの変更を自動的に反映する\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "educational-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from inputs import load_data\n",
    "# XGB\n",
    "from models import XGB\n",
    "# Torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from models import TrainingDataset, Torch, transform_labels, restore_labels, train_model, validate_model, \\\n",
    "                   TestDataset, predict_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-tackle",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "tutorial-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acute-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = None\n",
    "model = XGB(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cardiac-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x = train_x#[:80]\n",
    "va_x = train_x#[80:]\n",
    "tr_y = train_y#[:80]\n",
    "va_y = train_y#[80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "amber-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = 5\n",
    "model.fit(tr_x, tr_y, va_x, va_y,\n",
    "          early_stopping_rounds=early_stopping,\n",
    "          verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "existing-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afraid-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = test_x.index.to_numpy().reshape(-1, 1)\n",
    "preds = preds.reshape(-1, 1)\n",
    "submission = np.concatenate((index, preds), axis=1)\n",
    "submission = pd.DataFrame(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "blind-denmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('xgb.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-collection",
   "metadata": {},
   "source": [
    "## Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "agricultural-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TrainingDataset(target_transform = transform_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "electrical-bracelet",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.95\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "synthetic-handle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X torch.Size([6, 9])\n",
      "Shape of y torch.Size([6]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "for X, y in val_dataloader:\n",
    "    print('Shape of X', X.shape)\n",
    "    print('Shape of y', y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "included-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 9\n",
    "output_size = 6\n",
    "model = Torch(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "stopped-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "original-serve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 5.613350  [    0/  101]\n",
      "loss: 5.642447  [   20/  101]\n",
      "loss: 2.586769  [   40/  101]\n",
      "loss: 1.434297  [   60/  101]\n",
      "loss: 1.036397  [   80/  101]\n",
      "loss: 3.417500  [  100/  101]\n",
      "Test Error: \n",
      "Accuracy: 33.3%, Avg loss: 0.250084 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.788128  [    0/  101]\n",
      "loss: 1.334235  [   20/  101]\n",
      "loss: 1.270487  [   40/  101]\n",
      "loss: 0.999954  [   60/  101]\n",
      "loss: 1.153728  [   80/  101]\n",
      "loss: 2.629848  [  100/  101]\n",
      "Test Error: \n",
      "Accuracy: 16.7%, Avg loss: 0.286036 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.749056  [    0/  101]\n",
      "loss: 1.366430  [   20/  101]\n",
      "loss: 1.291510  [   40/  101]\n",
      "loss: 1.002410  [   60/  101]\n",
      "loss: 1.153626  [   80/  101]\n",
      "loss: 2.619985  [  100/  101]\n",
      "Test Error: \n",
      "Accuracy: 16.7%, Avg loss: 0.282554 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.743028  [    0/  101]\n",
      "loss: 1.364628  [   20/  101]\n",
      "loss: 1.290856  [   40/  101]\n",
      "loss: 1.000938  [   60/  101]\n",
      "loss: 1.152751  [   80/  101]\n",
      "loss: 2.610991  [  100/  101]\n",
      "Test Error: \n",
      "Accuracy: 33.3%, Avg loss: 0.279075 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.737081  [    0/  101]\n",
      "loss: 1.362789  [   20/  101]\n",
      "loss: 1.290208  [   40/  101]\n",
      "loss: 0.999522  [   60/  101]\n",
      "loss: 1.151953  [   80/  101]\n",
      "loss: 2.601894  [  100/  101]\n",
      "Test Error: \n",
      "Accuracy: 33.3%, Avg loss: 0.275674 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n-------------------------------')\n",
    "    train_model(train_dataloader, model, loss_fn, optimizer)\n",
    "    validate_model(val_dataloader, model, loss_fn)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "standing-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset()\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "preds = predict_test(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "incorrect-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [restore_labels(p) for p in preds]\n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "described-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "micro-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, test_x = load_data()\n",
    "index = test_x.index.to_numpy().reshape(-1, 1)\n",
    "preds = preds.reshape(-1, 1)\n",
    "submission = np.concatenate((index, preds), axis=1)\n",
    "submission = pd.DataFrame(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fifth-migration",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('torch.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-possession",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "intellectual-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "regional-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fleet-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = train_y.max()+1\n",
    "train_y = to_categorical(train_y, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "sunset-counter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 32)                320       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 8)                 264       \n",
      "=================================================================\n",
      "Total params: 584\n",
      "Trainable params: 584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (train_x.shape[1],)\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes, activation='relu')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "executed-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "favorite-inflation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 11.0594 - accuracy: 0.0396 - val_loss: 8.6244 - val_accuracy: 0.3333\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 10.9489 - accuracy: 0.3069 - val_loss: 8.5613 - val_accuracy: 0.3333\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 10.8784 - accuracy: 0.3069 - val_loss: 8.5228 - val_accuracy: 0.3333\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 10.8269 - accuracy: 0.3069 - val_loss: 8.4800 - val_accuracy: 0.3333\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 10.7882 - accuracy: 0.3069 - val_loss: 8.5124 - val_accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffd490368d0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-praise",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
