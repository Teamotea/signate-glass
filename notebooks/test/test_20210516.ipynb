{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "trained-medicaid",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "advanced-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一つ上の階層からモジュールを参照できるようにする\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "disturbed-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モジュールの変更を自動的に反映する\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "promising-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from inputs import load_data\n",
    "# # XGB\n",
    "from models import XGB\n",
    "# Torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from models import TrainingDataset, Torch, transform_labels, restore_labels, train_model, validate_model, \\\n",
    "                   TestDataset, predict_test\n",
    "# Keras\n",
    "from keras import Sequential, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-vampire",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "engaging-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "advanced-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = None\n",
    "model = XGB(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "portuguese-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x = train_x#[:80]\n",
    "va_x = train_x#[80:]\n",
    "tr_y = train_y#[:80]\n",
    "va_y = train_y#[80:]\n",
    "# tr_x = np.array([0 for _ in range(len(train_x))])\n",
    "# tr_x = tr_x.reshape(-1, 1)\n",
    "# va_x = tr_x\n",
    "# tr_y = np.array([0 for _ in range(len(train_y))])\n",
    "# va_y = tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "exotic-crawford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:01:03] WARNING: /Users/travis/build/dmlc/xgboost/src/predictor/cpu_predictor.cc:206: Ignoring the base margin, since it has incorrect length. The base margin must be an array of length [num_class] * [number of data points], i.e. 6 * 107 = 642. Instead, all data points will use base_score = 0.5\n",
      "[15:01:03] WARNING: /Users/travis/build/dmlc/xgboost/src/predictor/cpu_predictor.cc:206: Ignoring the base margin, since it has incorrect length. The base margin must be an array of length [num_class] * [number of data points], i.e. 6 * 107 = 642. Instead, all data points will use base_score = 0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "model.fit(tr_x, tr_y, va_x, va_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "female-recruitment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.27429\tvalidation_1-mlogloss:1.27429\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 5 rounds.\n",
      "[1]\tvalidation_0-mlogloss:0.98543\tvalidation_1-mlogloss:0.98543\n",
      "[2]\tvalidation_0-mlogloss:0.77405\tvalidation_1-mlogloss:0.77405\n",
      "[3]\tvalidation_0-mlogloss:0.61166\tvalidation_1-mlogloss:0.61166\n",
      "[4]\tvalidation_0-mlogloss:0.49693\tvalidation_1-mlogloss:0.49693\n",
      "[5]\tvalidation_0-mlogloss:0.40317\tvalidation_1-mlogloss:0.40317\n",
      "[6]\tvalidation_0-mlogloss:0.33250\tvalidation_1-mlogloss:0.33250\n",
      "[7]\tvalidation_0-mlogloss:0.27737\tvalidation_1-mlogloss:0.27737\n",
      "[8]\tvalidation_0-mlogloss:0.23674\tvalidation_1-mlogloss:0.23674\n",
      "[9]\tvalidation_0-mlogloss:0.20367\tvalidation_1-mlogloss:0.20367\n",
      "[10]\tvalidation_0-mlogloss:0.17655\tvalidation_1-mlogloss:0.17655\n",
      "[11]\tvalidation_0-mlogloss:0.15712\tvalidation_1-mlogloss:0.15712\n",
      "[12]\tvalidation_0-mlogloss:0.13919\tvalidation_1-mlogloss:0.13919\n",
      "[13]\tvalidation_0-mlogloss:0.12511\tvalidation_1-mlogloss:0.12511\n",
      "[14]\tvalidation_0-mlogloss:0.11400\tvalidation_1-mlogloss:0.11400\n",
      "[15]\tvalidation_0-mlogloss:0.10525\tvalidation_1-mlogloss:0.10525\n",
      "[16]\tvalidation_0-mlogloss:0.09642\tvalidation_1-mlogloss:0.09642\n",
      "[17]\tvalidation_0-mlogloss:0.09003\tvalidation_1-mlogloss:0.09003\n",
      "[18]\tvalidation_0-mlogloss:0.08430\tvalidation_1-mlogloss:0.08430\n",
      "[19]\tvalidation_0-mlogloss:0.07903\tvalidation_1-mlogloss:0.07903\n",
      "[20]\tvalidation_0-mlogloss:0.07450\tvalidation_1-mlogloss:0.07450\n",
      "[21]\tvalidation_0-mlogloss:0.07093\tvalidation_1-mlogloss:0.07093\n",
      "[22]\tvalidation_0-mlogloss:0.06805\tvalidation_1-mlogloss:0.06805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23]\tvalidation_0-mlogloss:0.06549\tvalidation_1-mlogloss:0.06549\n",
      "[24]\tvalidation_0-mlogloss:0.06355\tvalidation_1-mlogloss:0.06355\n",
      "[25]\tvalidation_0-mlogloss:0.06168\tvalidation_1-mlogloss:0.06168\n",
      "[26]\tvalidation_0-mlogloss:0.05987\tvalidation_1-mlogloss:0.05987\n",
      "[27]\tvalidation_0-mlogloss:0.05840\tvalidation_1-mlogloss:0.05840\n",
      "[28]\tvalidation_0-mlogloss:0.05697\tvalidation_1-mlogloss:0.05697\n",
      "[29]\tvalidation_0-mlogloss:0.05579\tvalidation_1-mlogloss:0.05579\n",
      "[30]\tvalidation_0-mlogloss:0.05449\tvalidation_1-mlogloss:0.05449\n",
      "[31]\tvalidation_0-mlogloss:0.05361\tvalidation_1-mlogloss:0.05361\n",
      "[32]\tvalidation_0-mlogloss:0.05269\tvalidation_1-mlogloss:0.05269\n",
      "[33]\tvalidation_0-mlogloss:0.05189\tvalidation_1-mlogloss:0.05189\n",
      "[34]\tvalidation_0-mlogloss:0.05107\tvalidation_1-mlogloss:0.05107\n",
      "[35]\tvalidation_0-mlogloss:0.05030\tvalidation_1-mlogloss:0.05030\n",
      "[36]\tvalidation_0-mlogloss:0.04951\tvalidation_1-mlogloss:0.04951\n",
      "[37]\tvalidation_0-mlogloss:0.04877\tvalidation_1-mlogloss:0.04877\n",
      "[38]\tvalidation_0-mlogloss:0.04811\tvalidation_1-mlogloss:0.04811\n",
      "[39]\tvalidation_0-mlogloss:0.04729\tvalidation_1-mlogloss:0.04729\n",
      "[40]\tvalidation_0-mlogloss:0.04646\tvalidation_1-mlogloss:0.04646\n",
      "[41]\tvalidation_0-mlogloss:0.04573\tvalidation_1-mlogloss:0.04573\n",
      "[42]\tvalidation_0-mlogloss:0.04525\tvalidation_1-mlogloss:0.04525\n",
      "[43]\tvalidation_0-mlogloss:0.04462\tvalidation_1-mlogloss:0.04462\n",
      "[44]\tvalidation_0-mlogloss:0.04402\tvalidation_1-mlogloss:0.04402\n",
      "[45]\tvalidation_0-mlogloss:0.04353\tvalidation_1-mlogloss:0.04353\n",
      "[46]\tvalidation_0-mlogloss:0.04305\tvalidation_1-mlogloss:0.04305\n",
      "[47]\tvalidation_0-mlogloss:0.04255\tvalidation_1-mlogloss:0.04255\n",
      "[48]\tvalidation_0-mlogloss:0.04215\tvalidation_1-mlogloss:0.04215\n",
      "[49]\tvalidation_0-mlogloss:0.04171\tvalidation_1-mlogloss:0.04171\n",
      "[50]\tvalidation_0-mlogloss:0.04132\tvalidation_1-mlogloss:0.04132\n",
      "[51]\tvalidation_0-mlogloss:0.04099\tvalidation_1-mlogloss:0.04099\n",
      "[52]\tvalidation_0-mlogloss:0.04059\tvalidation_1-mlogloss:0.04059\n",
      "[53]\tvalidation_0-mlogloss:0.04030\tvalidation_1-mlogloss:0.04030\n",
      "[54]\tvalidation_0-mlogloss:0.03997\tvalidation_1-mlogloss:0.03997\n",
      "[55]\tvalidation_0-mlogloss:0.03968\tvalidation_1-mlogloss:0.03968\n",
      "[56]\tvalidation_0-mlogloss:0.03934\tvalidation_1-mlogloss:0.03934\n",
      "[57]\tvalidation_0-mlogloss:0.03911\tvalidation_1-mlogloss:0.03911\n",
      "[58]\tvalidation_0-mlogloss:0.03883\tvalidation_1-mlogloss:0.03883\n",
      "[59]\tvalidation_0-mlogloss:0.03864\tvalidation_1-mlogloss:0.03864\n",
      "[60]\tvalidation_0-mlogloss:0.03841\tvalidation_1-mlogloss:0.03841\n",
      "[61]\tvalidation_0-mlogloss:0.03820\tvalidation_1-mlogloss:0.03820\n",
      "[62]\tvalidation_0-mlogloss:0.03804\tvalidation_1-mlogloss:0.03804\n",
      "[63]\tvalidation_0-mlogloss:0.03787\tvalidation_1-mlogloss:0.03787\n",
      "[64]\tvalidation_0-mlogloss:0.03772\tvalidation_1-mlogloss:0.03772\n",
      "[65]\tvalidation_0-mlogloss:0.03755\tvalidation_1-mlogloss:0.03755\n",
      "[66]\tvalidation_0-mlogloss:0.03742\tvalidation_1-mlogloss:0.03742\n",
      "[67]\tvalidation_0-mlogloss:0.03727\tvalidation_1-mlogloss:0.03727\n",
      "[68]\tvalidation_0-mlogloss:0.03712\tvalidation_1-mlogloss:0.03712\n",
      "[69]\tvalidation_0-mlogloss:0.03703\tvalidation_1-mlogloss:0.03703\n",
      "[70]\tvalidation_0-mlogloss:0.03688\tvalidation_1-mlogloss:0.03688\n",
      "[71]\tvalidation_0-mlogloss:0.03672\tvalidation_1-mlogloss:0.03672\n",
      "[72]\tvalidation_0-mlogloss:0.03658\tvalidation_1-mlogloss:0.03658\n",
      "[73]\tvalidation_0-mlogloss:0.03649\tvalidation_1-mlogloss:0.03649\n",
      "[74]\tvalidation_0-mlogloss:0.03636\tvalidation_1-mlogloss:0.03636\n",
      "[75]\tvalidation_0-mlogloss:0.03620\tvalidation_1-mlogloss:0.03620\n",
      "[76]\tvalidation_0-mlogloss:0.03608\tvalidation_1-mlogloss:0.03608\n",
      "[77]\tvalidation_0-mlogloss:0.03597\tvalidation_1-mlogloss:0.03597\n",
      "[78]\tvalidation_0-mlogloss:0.03585\tvalidation_1-mlogloss:0.03585\n",
      "[79]\tvalidation_0-mlogloss:0.03574\tvalidation_1-mlogloss:0.03574\n",
      "[80]\tvalidation_0-mlogloss:0.03567\tvalidation_1-mlogloss:0.03567\n",
      "[81]\tvalidation_0-mlogloss:0.03552\tvalidation_1-mlogloss:0.03552\n",
      "[82]\tvalidation_0-mlogloss:0.03542\tvalidation_1-mlogloss:0.03542\n",
      "[83]\tvalidation_0-mlogloss:0.03535\tvalidation_1-mlogloss:0.03535\n",
      "[84]\tvalidation_0-mlogloss:0.03524\tvalidation_1-mlogloss:0.03524\n",
      "[85]\tvalidation_0-mlogloss:0.03513\tvalidation_1-mlogloss:0.03513\n",
      "[86]\tvalidation_0-mlogloss:0.03506\tvalidation_1-mlogloss:0.03506\n",
      "[87]\tvalidation_0-mlogloss:0.03493\tvalidation_1-mlogloss:0.03493\n",
      "[88]\tvalidation_0-mlogloss:0.03487\tvalidation_1-mlogloss:0.03487\n",
      "[89]\tvalidation_0-mlogloss:0.03477\tvalidation_1-mlogloss:0.03477\n",
      "[90]\tvalidation_0-mlogloss:0.03466\tvalidation_1-mlogloss:0.03466\n",
      "[91]\tvalidation_0-mlogloss:0.03456\tvalidation_1-mlogloss:0.03456\n",
      "[92]\tvalidation_0-mlogloss:0.03450\tvalidation_1-mlogloss:0.03450\n",
      "[93]\tvalidation_0-mlogloss:0.03441\tvalidation_1-mlogloss:0.03441\n",
      "[94]\tvalidation_0-mlogloss:0.03435\tvalidation_1-mlogloss:0.03435\n",
      "[95]\tvalidation_0-mlogloss:0.03425\tvalidation_1-mlogloss:0.03425\n",
      "[96]\tvalidation_0-mlogloss:0.03416\tvalidation_1-mlogloss:0.03416\n",
      "[97]\tvalidation_0-mlogloss:0.03407\tvalidation_1-mlogloss:0.03407\n",
      "[98]\tvalidation_0-mlogloss:0.03401\tvalidation_1-mlogloss:0.03401\n",
      "[99]\tvalidation_0-mlogloss:0.03392\tvalidation_1-mlogloss:0.03392\n"
     ]
    }
   ],
   "source": [
    "early_stopping = 5\n",
    "model.fit(tr_x, tr_y, va_x, va_y,\n",
    "          early_stopping_rounds=early_stopping,\n",
    "          verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "insured-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = test_x.index.to_numpy().reshape(-1, 1)\n",
    "preds = preds.reshape(-1, 1)\n",
    "submission = np.concatenate((index, preds), axis=1)\n",
    "submission = pd.DataFrame(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "detected-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('xgb.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-algeria",
   "metadata": {},
   "source": [
    "## Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "determined-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TrainingDataset(target_transform = transform_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "pressing-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.95\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "restricted-gambling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X torch.Size([6, 9])\n",
      "Shape of y torch.Size([6]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "for X, y in val_dataloader:\n",
    "    print('Shape of X', X.shape)\n",
    "    print('Shape of y', y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "forbidden-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 9\n",
    "output_size = 6\n",
    "model = Torch(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "nutritional-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "reserved-booking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.796193  [    0/  101]\n",
      "loss: 1.775526  [   20/  101]\n",
      "loss: 1.795517  [   40/  101]\n",
      "loss: 1.787526  [   60/  101]\n",
      "loss: 1.784987  [   80/  101]\n",
      "loss: 1.875845  [  100/  101]\n",
      "Test Error: \n",
      "Accuracy: 16.7%, Avg loss: 0.306299 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.795148  [    0/  101]\n",
      "loss: 1.775630  [   20/  101]\n",
      "loss: 1.796246  [   40/  101]\n",
      "loss: 1.788041  [   60/  101]\n",
      "loss: 1.785111  [   80/  101]\n",
      "loss: 1.871614  [  100/  101]\n",
      "Test Error: \n",
      "Accuracy: 16.7%, Avg loss: 0.305924 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.794282  [    0/  101]\n",
      "loss: 1.775714  [   20/  101]\n",
      "loss: 1.796897  [   40/  101]\n",
      "loss: 1.788494  [   60/  101]\n",
      "loss: 1.785205  [   80/  101]\n",
      "loss: 1.868060  [  100/  101]\n",
      "Test Error: \n",
      "Accuracy: 16.7%, Avg loss: 0.305613 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.793576  [    0/  101]\n",
      "loss: 1.775770  [   20/  101]\n",
      "loss: 1.797454  [   40/  101]\n",
      "loss: 1.788868  [   60/  101]\n",
      "loss: 1.785265  [   80/  101]\n",
      "loss: 1.865156  [  100/  101]\n",
      "Test Error: \n",
      "Accuracy: 0.0%, Avg loss: 0.305361 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.793004  [    0/  101]\n",
      "loss: 1.775794  [   20/  101]\n",
      "loss: 1.797907  [   40/  101]\n",
      "loss: 1.789159  [   60/  101]\n",
      "loss: 1.785291  [   80/  101]\n",
      "loss: 1.862840  [  100/  101]\n",
      "Test Error: \n",
      "Accuracy: 0.0%, Avg loss: 0.305161 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n-------------------------------')\n",
    "    train_model(train_dataloader, model, loss_fn, optimizer)\n",
    "    validate_model(val_dataloader, model, loss_fn)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "rental-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset()\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "preds = predict_test(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "divine-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [restore_labels(p) for p in preds]\n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "portable-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "retained-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, test_x = load_data()\n",
    "index = test_x.index.to_numpy().reshape(-1, 1)\n",
    "preds = preds.reshape(-1, 1)\n",
    "submission = np.concatenate((index, preds), axis=1)\n",
    "submission = pd.DataFrame(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "corresponding-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('torch.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-pharmacology",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "pleasant-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_FOR_SUBMISSION = True\n",
    "validation_split = 0.0 if TRAINING_FOR_SUBMISSION else 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "extraordinary-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "multiple-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_y.unique())\n",
    "train_y = pd.get_dummies(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "religious-tomorrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_66 (Dense)             (None, 64)                640       \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 5,190\n",
      "Trainable params: 5,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (train_x.shape[1],)\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "found-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "cognitive-beijing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11/11 [==============================] - 0s 852us/step - loss: 8.0530 - accuracy: 0.1682\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 0s 789us/step - loss: 3.1567 - accuracy: 0.3551\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 0s 829us/step - loss: 2.0668 - accuracy: 0.3178\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 0s 903us/step - loss: 1.8164 - accuracy: 0.3738\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 0s 933us/step - loss: 1.5992 - accuracy: 0.4112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff84bd31290>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "quantitative-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train_y.columns.tolist()\n",
    "preds = model.predict(test_x).argmax(axis=1)\n",
    "preds = [classes[pred] for pred in preds]\n",
    "preds = np.array(preds)\n",
    "preds = preds.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "studied-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "supposed-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = test_x.index.to_numpy().reshape(-1, 1)\n",
    "submission = np.concatenate((index, preds), axis=1)\n",
    "submission = pd.DataFrame(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "communist-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('keras.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-brick",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
